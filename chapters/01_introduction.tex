% !TeX root = ../main.tex

\chapter{Introduction}\label{chapter:introduction}
Despite the fact that High Driving Automation(SAE Level 4) is achievable in the foreseeable future\cite{inagaki2019critique}, the majority of drivers nowadays would still prefer comprehensive control over their own vehicles. Therefore, increasingly more studies have been focusing on driving safety\cite{lee2005driving}\cite{lee2008fifty}. 
According to these papers, driver behavior represents the majority cause of accidents while driving. In that case, several methods have been developed to avoid potential danger. Such methods involve Either improving monitoring of the vehicle's inside situation, which analyzes the driving parameters as well as the driver him or herself to determine whether there's no abnormality \cite{karrouchi2023driving}, or proposing a vehicle detection and tracking system from an outer view that estimates time-to-collision (TTC) and warn the driver for a possible collision\cite{aytekin2010increasing}.

On the other hand, only few research focus on driving behavior prediction, which may be due to the lack of application for the undetermined decision model in behavior prediction, specifically under the topic of autonomous driving. Scientists have succeeded in years of generating dynamic graphs based on videos. However, there is still a gap in the rational use of these forms for behavioral prediction.

In this work, we would like to focus on constructing a comprehensive behavior prediction model based on graph neural networks (GNNs). A Graph Neural Network is a novel type of neural network architecture that can be applied to graph-like inputs. As we are now expecting to train the behavior model for the participators, the training data would contain interaction between several objects and participators while they are driving. GNN is, therefore, prioritized due to its unique structure. Along with that, we would specifically focus on building dynamic graphs as training datasets, as our model would be trained based on sequences of behaviour descriptions extracted from videos.
Besides, to ensure the compatibility of the dataset and training model, we made some adaptions based on JODIE\cite{kumar2019predicting}, which is the model based on the dynamic evolution of users and items. In order to make the predictions as detailed as possible, we expanded the output catalogue to ensure that not only the interaction itself but also the type of it would be described.

Specifically speaking, We would first gather all the necessary information with the help of the Large language model(LLM), convert it into dynamic graphs and insert these graphs into the model we have adapted from JODIE. By learning the appearance and vanish of all these edges and nodes in the graph, the model should be able to absorb the feature behind it and come up with the prediction for behaviour in the future. The results demonstrate the capacity of using captured video for feature learning, predicting future behaviours and giving warnings when anomalous.


\section{contribution}
The main contributions of this thesis are summarized as:
\begin{itemize}
    % dynamic graph
    \item From the Dataset \textit{Drive&Act}, we could acquire the hierarchical activity labels of given video data. In this work, we gather 
    % learning
    % 
\end{itemize}


\section{Structure}

This thesis is structured as follows. In Chapter \ref{chapter:background} we would introduce and explain concepts and definitions concerned to this document. Chapter \ref{chapter:relatedwork}





